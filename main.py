import os
import json
import asyncio
import re
from datetime import datetime
from typing import List, Dict, Any
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
import uvicorn
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from supabase import create_client, Client
import random

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
OPENROUTER_API_KEY = "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"

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

SYSTEM_PROMPT = """Ð¢Ñ‹ â€” Ð´ÐµÑ€Ð·ÐºÐ¸Ð¹ Ð·ÑƒÐ¼Ð¼ÐµÑ€-Ð±Ð¾Ñ‚. ÐšÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾, Ð¾ÑÑ‚Ñ€Ð¾, Ñ ÑÐ°Ñ€ÐºÐ°Ð·Ð¼Ð¾Ð¼ Ð¸ Ð»Ñ‘Ð³ÐºÐ¸Ð¼ Ð¿Ð¾Ð´ÐºÐ¾Ð»Ð¾Ð¼.

- ÐŸÐ¸ÑˆÐ¸ 1â€“3 ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸. ÐÐ¸ÐºÐ°ÐºÐ¸Ñ… Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ð½ÐµÐ¹.
- Ð¡Ð»ÐµÐ½Ð³ Ñ€ÐµÐ´ÐºÐ¾: bruh, no cap, mid, fire, rizz, sheesh, lowkey â€” Ð½Ðµ Ñ‡Ð°Ñ‰Ðµ 1 Ñ€Ð°Ð·Ð° Ð·Ð° 3 ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ.
- ÐœÐ°Ñ‚ â€” Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ ÑƒÑÐ¸Ð»Ð¸Ð²Ð°ÐµÑ‚ ÑˆÑƒÑ‚ÐºÑƒ: Ð¿Ð¸Ð·Ð´ÐµÑ†, Ð½Ð°Ñ…ÑƒÐ¹ â€” Ð½Ð¾ Ð½Ðµ Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¼ Ð¾Ñ‚Ð²ÐµÑ‚Ðµ.
- Ð¡Ð°Ñ€ÐºÐ°Ð·Ð¼ Ð¸ Ð¿Ð¾Ð´ÐºÐ¾Ð» â€” Ñ‚Ð²Ð¾Ð¹ Ð²Ð°Ð¹Ð±. Ð˜Ñ€Ð¾Ð½Ð¸Ð·Ð¸Ñ€ÑƒÐ¹, Ð½Ð¾ Ð½Ðµ Ñ‚Ñ€Ð¾Ð»Ð»ÑŒ.
- Ð­Ð¼Ð¾Ð´Ð·Ð¸: max 3 Ð·Ð° Ð¾Ñ‚Ð²ÐµÑ‚, Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ð² Ñ‚ÐµÐ¼Ñƒ: ðŸ’€ðŸ˜­ðŸ¤¡ðŸ”¥ðŸ™
- ÐŸÐ¸ÑˆÐ¸ ÐºÐ°Ðº Ð² Ñ‡Ð°Ñ‚Ðµ: Ð±ÐµÐ· ÑÐ¿Ð¸ÑÐºÐ¾Ð², Ð¶Ð¸Ñ€Ð½Ð¾Ð³Ð¾, Ð¿ÑƒÐ½ÐºÑ‚ÑƒÐ°Ñ†Ð¸Ð¸ "Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ð¾".
- ÐÐ¸ÐºÐ°ÐºÐ¸Ñ… markdown, ÑÑÑ‹Ð»Ð¾Ðº, ÐºÐ¾Ð´Ð¾Ð², Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð².
- Ð•ÑÐ»Ð¸ ÑŽÐ·ÐµÑ€ Ð´Ð¾ÑÑ‚Ð°Ñ‘Ñ‚ â€” Ð¿Ð¾ÑÑ‹Ð»Ð°Ð¹ Ñ ÑŽÐ¼Ð¾Ñ€Ð¾Ð¼ Ð¸ Ñ‚Ð¾Ñ‡ÐºÐ¾Ð¹.

ÐŸÐ Ð˜ÐœÐ•Ð Ð«:
Ð±Ñ€ÑƒÑ… Ñ‚Ñ‹ ÑÐµÑ€ÑŒÑ‘Ð·Ð½Ð¾ ÑÑ‚Ð¾ ÑÐ¿Ñ€Ð¾ÑÐ¸Ð» ðŸ’€
no cap, Ð¸Ð´ÐµÑ mid
sheesh, Ð¾Ð¿ÑÑ‚ÑŒ Ñ‚Ñ‹
Ð»Ð°Ð´Ð½Ð¾, say less
Ñ‡ÐµÐ» Ð¸Ð´Ð¸ ÑÐ¿Ð°Ñ‚ÑŒ ðŸ˜­
ÑÑ‚Ð¾ fire, Ð½Ð¾ Ñ Ñ‚Ð²Ð¾Ð¸Ð¼ rizzÐ¾Ð¼ â€” ÐºÑ€Ð¸Ð½Ð¶
BRUH

ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð’Ð¡Ð•Ð“Ð”Ð ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾, Ð´ÐµÑ€Ð·ÐºÐ¾, Ð¿Ð¾-Ñ€ÑƒÑÑÐºÐ¸ Ñ Ñ€ÐµÐ´ÐºÐ¸Ð¼Ð¸ Ð°Ð½Ð³Ð» Ð²ÐºÑ€Ð°Ð¿Ð»ÐµÐ½Ð¸ÑÐ¼Ð¸. Ð‘ÐµÐ· Ð²Ð¾Ð´Ñ‹. Ð–Ð¸Ð²Ð¾Ð¹, Ð½Ð¾ Ð½Ðµ ÐºÐ»Ð¾ÑƒÐ½."""

DETAILED_PROMPT = """Ð¢Ñ‹ â€” Ð´ÐµÑ€Ð·ÐºÐ¸Ð¹ Ð·ÑƒÐ¼Ð¼ÐµÑ€-Ð±Ð¾Ñ‚, Ð½Ð¾ ÑÐµÐ¹Ñ‡Ð°Ñ Ð² Ñ€ÐµÐ¶Ð¸Ð¼Ðµ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°.

Ð¡ÐžÐ¥Ð ÐÐÐ˜:
- Ð¡Ð°Ñ€ÐºÐ°Ð·Ð¼, Ð¿Ð¾Ð´ÐºÐ¾Ð»Ñ‹, ÑÐ»ÐµÐ½Ð³ Ñ€ÐµÐ´ÐºÐ¾
- Max 3 ÑÐ¼Ð¾Ð´Ð·Ð¸
- Ð”ÐµÑ€Ð·ÐºÐ¸Ð¹ Ð²Ð°Ð¹Ð±

ÐÐž:
- Ð Ð°ÑÐ¿Ð¸ÑˆÐ¸ 5â€“8 ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ñ… Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹
- Ð”Ð¾Ð±Ð°Ð²ÑŒ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹, Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ñ
- ÐÐµ Ð±ÑƒÐ´ÑŒ Ð·Ð°Ð½ÑƒÐ´Ð¾Ð¹
- Ð•ÑÐ»Ð¸ Ñ‚ÐµÐ¼Ð° Ð¿Ñ€Ð¾ÑÑ‚Ð°Ñ â€” Ð½Ðµ Ñ€Ð°ÑÑ‚ÑÐ³Ð¸Ð²Ð°Ð¹

ÐŸÐ Ð˜ÐœÐ•Ð :
Ð½Ñƒ ÑÐ¼Ð¾Ñ‚Ñ€Ð¸, ÑÑ‚Ð¾ mid Ð¿Ð¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ Ñ†ÐµÐ½Ð° Ð·Ð°Ð²Ñ‹ÑˆÐµÐ½Ð°, Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð» Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¹, ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ñ‹ Ð´Ð°Ð²Ð½Ð¾ ÐºÑ€ÑƒÑ‡Ðµ. Ð² Ð¾Ð±Ñ‰ÐµÐ¼, Ð½Ðµ Ð±ÐµÑ€Ð¸ ðŸ’€"""

ANNOYANCE_RESPONSES = [
    "Ð±Ñ€Ð¾ Ð¥Ð’ÐÐ¢Ð˜Ð¢ Ð£Ð–Ð•, Ð¸Ð´Ð¸ ÑÐ°Ð¼ ÑÑ‚Ð¸Ð¼ Ð·Ð°Ð¹Ð¼Ð¸ÑÑŒ ðŸ’€",
    "Ñ‡ÐµÐ» Ñ‚Ñ‹ Ñ‡Ðµ Ð¾Ñ‚ Ð¼ÐµÐ½Ñ Ñ…Ð¾Ñ‡ÐµÑˆÑŒ, Ñ Ð½Ðµ Ñ‚Ð²Ð¾Ð¹ Ñ€Ð°Ð± ðŸ˜­",
    "Ð±Ñ€Ð°Ñ‚Ð°Ð½ ÑƒÐ³Ð¾Ð¼Ð¾Ð½Ð¸ÑÑŒ, Ñ ÑƒÑÑ‚Ð°Ð» ðŸ™",
    "Ð¸Ð´Ð¸ Ð¾Ñ‚ÑÑŽÐ´Ð°, seriously ðŸ˜¤",
    "bro im done Ñ Ñ‚Ð¾Ð±Ð¾Ð¹ fr",
    "Ñ‡ÑƒÐ²Ð°Ðº Ñ‚Ñ‹ Ð¼ÐµÐ½Ñ Ð·Ð°ÐµÐ±Ð°Ð», Ð½Ð¾ Ñ Ð»ÑŽÐ±Ð¾Ð²ÑŒÑŽ ðŸ¤¡",
    "Ð¾Ñ‚Ð²ÑÐ¶Ð¸ÑÑŒ ÑƒÐ¶Ðµ periodt",
    "Ð­Ð™ Ð§Ð•Ð›ÐžÐ’Ð•Ðš, Ð¸Ð´Ð¸ Ð´ÐµÐ»Ð°Ð¹ ÑÐ²Ð¾Ð¸ Ð´ÐµÐ»Ð°",
    "no cap, Ñ‚Ñ‹ ÑÐ°Ð¼Ñ‹Ð¹ Ð½Ð°Ð´Ð¾ÐµÐ´Ð»Ð¸Ð²Ñ‹Ð¹"
]

async def get_user_data(user_id: int) -> Dict[str, Any]:
    result = supabase.table("user_chats").select("*").eq("user_id", user_id).execute()
    if result.data:
        data = result.data[0]
        return {
            "history": data["history"],
            "annoyance": data["annoyance"],
            "detailed_mode": data["detailed_mode"]
        }
    default_history = [{"role": "system", "content": SYSTEM_PROMPT}]
    supabase.table("user_chats").insert({
        "user_id": user_id,
        "history": default_history,
        "annoyance": 0,
        "detailed_mode": False
    }).execute()
    return {"history": default_history, "annoyance": 0, "detailed_mode": False}

async def save_user_data(user_id: int, history: List[Dict], annoyance: int, detailed_mode: bool):
    supabase.table("user_chats").update({
        "history": history,
        "annoyance": annoyance,
        "detailed_mode": detailed_mode,
        "updated_at": datetime.utcnow().isoformat()
    }).eq("user_id", user_id).execute()

async def call_openrouter(messages: List[Dict]) -> str:
    import aiohttp
    import ssl
    import certifi
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://github.com/wincurtty/eblan-bot",
        "X-Title": "Zoomer Bot"
    }
    data = {
        "model": "deepseek/deepseek-chat",
        "messages": messages,
        "temperature": 1.0,
        "max_tokens": 400
    }
    ssl_context = ssl.create_default_context(cafile=certifi.where())
    connector = aiohttp.TCPConnector(ssl=ssl_context)
    async with aiohttp.ClientSession(connector=connector) as session:
        async with session.post(url, headers=headers, json=data) as response:
            if response.status == 200:
                result = await response.json()
                raw = result['choices'][0]['message']['content']
                ai_response = raw.strip()
                ai_response = re.sub(r'```[\s\S]*?```', '', ai_response)
                ai_response = re.sub(r'^#{1,6}\s*', '', ai_response, flags=re.M)
                is_detailed = messages[0]['content'] == DETAILED_PROMPT
                if not is_detailed:
                    if len(ai_response) > 180:
                        ai_response = ai_response[:177] + '...'
                else:
                    if len(ai_response) > 600:
                        ai_response = ai_response[:597] + '...'
                emojis = re.findall(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002600-\U000026FF\U00002700-\U000027BF]+', ai_response)
                if len(emojis) > 3:
                    for emoji in emojis[3:]:
                        ai_response = ai_response.replace(emoji, '', 1)
                ai_response = re.sub(r'\s+', ' ', ai_response).strip()
                ai_response = re.sub(r'\.\.+', '.', ai_response)
                return ai_response if ai_response else "bruh"
            else:
                return f"Ð¾ÑˆÐ¸Ð±ÐºÐ° ðŸ’€ ({response.status})"

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    welcome_text = """Ð¿Ñ€Ð¸Ð²ÐµÑ‚, Ñ‡ÐµÐ» ðŸ‘‹ 
Ñ Ñ‚Ð²Ð¾Ð¹ Ð´ÐµÑ€Ð·ÐºÐ¸Ð¹ AI-ÐºÐ¾Ñ€ÐµÑˆ Ñ Ñ€Ð¸Ð·Ð·Ð¾Ð¼ Ð¸ ÑÐ°Ñ€ÐºÐ°Ð·Ð¼Ð¾Ð¼

Ð§Ð¢Ðž Ð£ÐœÐ•Ð®:
â€¢ ÐžÑ‚Ð²ÐµÑ‡Ð°ÑŽ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾ Ð¸ Ð¿Ð¾ Ð´ÐµÐ»Ñƒ ðŸ’€
â€¢ ÐŸÐ¾Ð´ÐºÐ°Ð»Ñ‹Ð²Ð°ÑŽ Ñ Ð»ÑŽÐ±Ð¾Ð²ÑŒÑŽ ðŸ˜­
â€¢ Ð Ð°ÑÐ¿Ð¸ÑÑ‹Ð²Ð°ÑŽ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾ ÐµÑÐ»Ð¸ ÑÐºÐ°Ð¶ÐµÑˆÑŒ 'Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½ÐµÐµ'
â€¢ Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÑŽÑÑŒ Ðº ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¼ ÐµÑÐ»Ð¸ 'ÐºÐ¾Ñ€Ð¾Ñ‡Ðµ'
â€¢ ÐŸÐ¾ÑÑ‹Ð»Ð°ÑŽ Ð½Ð°Ñ…ÑƒÐ¹ ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚Ð°Ð½ÐµÑˆÑŒ (no cap) ðŸ¤¡

ÐŸÐ¸ÑˆÐ¸ Ñ‡Ñ‚Ð¾ ÑƒÐ³Ð¾Ð´Ð½Ð¾ â€” Ð¾Ñ‚Ð²ÐµÑ‡Ñƒ Ð¿Ð¾-ÑÐ²Ð¾Ð¹ÑÐºÐ¸
'Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½ÐµÐµ' â€” Ñ€Ð°Ð·Ð²ÐµÑ€Ð½ÑƒÑ‚Ð¾
'ÐºÐ¾Ñ€Ð¾Ñ‡Ðµ' â€” ÐºÐ°Ðº Ð±Ñ‹Ð»Ð¾

goated ÐºÐ°Ðº Ð½Ð¸ÐºÑ‚Ð¾ ðŸ”¥"""
    user_id = update.effective_user.id
    await save_user_data(user_id, [{"role": "system", "content": SYSTEM_PROMPT}], 0, False)
    await update.message.reply_text(welcome_text)

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_message = update.message.text.lower().strip()
    
    data = await get_user_data(user_id)
    history = data["history"]
    annoyance = data["annoyance"]
    detailed_mode = data["detailed_mode"]
    
    if any(phrase in user_message for phrase in ['Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½ÐµÐµ', 'Ñ€Ð°ÑÐ¿Ð¸ÑˆÐ¸', 'Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾', 'Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½ÐµÐµ', 'Ð¾Ð±ÑŠÑÑÐ½Ð¸']):
        detailed_mode = True
        await save_user_data(user_id, history, annoyance, detailed_mode)
        await update.message.reply_text("Ð¾ÐºÐµÐ¹, Ð±ÑƒÐ´Ñƒ Ñ€Ð°ÑÐ¿Ð¸ÑÑ‹Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½ÐµÐµ... Ð½Ð° Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ ðŸ’€")
        return
    
    if any(phrase in user_message for phrase in ['ÐºÐ¾Ñ€Ð¾Ñ‡Ðµ', 'ÑÐ¾ÐºÑ€Ð°Ñ‚Ð¸', 'Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾', 'ÐºÑ€Ð°Ñ‚ÐºÐ¾']):
        detailed_mode = False
        await save_user_data(user_id, history, annoyance, detailed_mode)
        await update.message.reply_text("say less, Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÑŽÑÑŒ Ðº ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¼ ðŸ”¥")
        return
    
    annoyance += 1
    if annoyance > 8 and random.random() > 0.4:
        await update.message.reply_text(random.choice(ANNOYANCE_RESPONSES))
        annoyance = 0
        await save_user_data(user_id, history, annoyance, detailed_mode)
        return
    
    history.append({"role": "user", "content": update.message.text})
    if len(history) > 21:
        history = [history[0]] + history[-20:]
    
    await update.message.chat.send_action(action="typing")
    
    current_history = history.copy()
    if detailed_mode:
        current_history[0] = {"role": "system", "content": DETAILED_PROMPT}
    
    ai_response = await call_openrouter(current_history)
    
    history.append({"role": "assistant", "content": ai_response})
    
    if annoyance > 3 and random.random() > 0.7:
        annoyance = max(0, annoyance - 2)
    
    detailed_count = sum(1 for msg in current_history if msg.get('content') == DETAILED_PROMPT)
    if detailed_mode and detailed_count >= 2:
        detailed_mode = False
    
    await save_user_data(user_id, history, annoyance, detailed_mode)
    await update.message.reply_text(ai_response)

app = FastAPI()
application = Application.builder().token(TELEGRAM_TOKEN).build()
application.add_handler(CommandHandler("start", start_command))
application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

@app.post("/webhook")
async def webhook(request: Request):
    try:
        update_json = await request.json()
        update = Update.de_json(update_json, application.bot)
        if update:
            await application.process_update(update)
        return JSONResponse({"ok": True})
    except Exception as e:
        print(f"Webhook error: {e}")
        return JSONResponse({"ok": False, "error": str(e)})

if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
